// Package lexer is generated by GoGLL. Do not edit.
package lexer

import (
	"unicode"

	"github.com/goccmack/gogll/token"
)

func New(input []rune) *Lexer {
	lex := &Lexer{
		I:      input,
		Tokens: make([]*token.Token, 0, 2048),
		pos:    0,
	}
	lex.scan()
	lex.add(token.EOF, len(input), len(input))
	return lex
}

func (l *Lexer) scan() {
	for l.pos < len(l.I) {
		l.skipWhiteSpace()
		if l.pos >= len(l.I) {
			return
		}

		lext := l.pos
		l.pos++
		switch l.I[lext] {
		case '(':
			l.add(token.Type0, lext, l.pos)
		case ')':
			l.add(token.Type1, lext, l.pos)
		case '.':
			l.add(token.Type2, lext, l.pos)
		case ':':
			l.add(token.Type3, lext, l.pos)
		case ';':
			l.add(token.Type4, lext, l.pos)
		case '<':
			l.add(token.Type5, lext, l.pos)
		case '>':
			l.add(token.Type6, lext, l.pos)
		case '[':
			l.add(token.Type7, lext, l.pos)
		case ']':
			l.add(token.Type8, lext, l.pos)
		case '{':
			l.add(token.Type22, lext, l.pos)
		case '|':
			l.add(token.Type23, lext, l.pos)
		case '}':
			l.add(token.Type24, lext, l.pos)
		case '"': // Type19
			l.scanStringLiteral(lext)
		case '\'': // Type10
			l.scanCharLit(lext)
		default:
			switch {
			case unicode.IsLower(l.I[lext]): // Type20 tokid or res word
				l.scanTokIDOrReserevedWord(lext)
			case unicode.IsUpper((l.I[lext])): // Type15 nt
				l.scanNT(lext)
			default:
				l.add(token.Error, lext, l.pos)
			}
		}
	}
}

func (l *Lexer) scanCharLit(lext int) {
	if l.I[l.pos] == '\\' {
		l.pos++
		switch l.I[l.pos] {
		case '\\', '\'', 'n', 'r', 't':
			// OK
		default:
			l.add(token.Error, lext, l.pos)
			return
		}
	}
	l.pos++
	if l.I[l.pos] != '\'' {
		l.add(token.Error, lext, l.pos)
	} else {
		l.pos++
		l.add(token.Type10, lext, l.pos)
	}
}

func (l *Lexer) scanNT(lext int) {
	for l.isIDChar() {
		l.pos++
	}
	l.add(token.Type15, lext, l.pos)
}

func (l *Lexer) scanTokIDOrReserevedWord(lext int) {
	for l.isIDChar() {
		l.pos++
	}
	switch string(l.I[lext:l.pos]) {
	case "any":
		l.add(token.Type9, lext, l.pos)
	case "empty":
		l.add(token.Type11, lext, l.pos)
	case "letter":
		l.add(token.Type12, lext, l.pos)
	case "lowcase":
		l.add(token.Type13, lext, l.pos)
	case "not":
		l.add(token.Type14, lext, l.pos)
	case "number":
		l.add(token.Type16, lext, l.pos)
	case "package":
		l.add(token.Type17, lext, l.pos)
	case "space":
		l.add(token.Type18, lext, l.pos)
	case "upcase":
		l.add(token.Type21, lext, l.pos)
	default: // tokid
		l.add(token.Type20, lext, l.pos)
	}
}

func (l *Lexer) isIDChar() bool {
	if l.pos >= len(l.I) {
		return false
	}
	c := l.I[l.pos]
	return unicode.IsLetter(c) || unicode.IsNumber(c) || c == '_'
}

func (l *Lexer) scanStringLiteral(lext int) {
	for l.pos < len(l.I) && l.I[l.pos] != '"' {
		if l.I[l.pos] == '\\' {
			l.pos++
			switch l.I[l.pos] {
			case '\\', '"', 'n', 'r', 't':
				// OK
			default:
				l.pos++
				l.add(token.Error, lext, l.pos)
				return
			}
		}
		l.pos++
	}
	if l.pos >= len(l.I) || l.I[l.pos] != '"' {
		l.add(token.Error, lext, l.pos)
	} else {
		l.pos++
		l.add(token.Type19, lext, l.pos)
	}
}
