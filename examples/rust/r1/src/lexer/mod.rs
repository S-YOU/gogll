
//! Module lexer is generated by GoGLL. Do not edit.

extern crate lazy_static;

use crate::token;

use std::collections::HashMap;
use std::{fs, io};
use std::rc::Rc;
use lazy_static::lazy_static;

type State = usize;

const NULL_STATE: State = usize::MAX ;

/**
Lexer contains both the input Vec<char> and the Vec<token::Token>
parsed from the input
*/
pub struct Lexer {
	/// i is the input vector of char
	i: Rc<Vec<char>>,

	/// tokens is the vector of tokens constructed by the lexer from I
	tokens: Vec<Rc<token::Token>>
}

impl Lexer {
	/**
	new_file constructs a Lexer created from the input file, fname. 

	If the input file is a markdown file new_file process treats all text outside
	code blocks as whitespace. All text inside code blocks are treated as input text.

	If the input file is a normal text file new_file treats all text in the inputfile
	as input text.
	*/
	#[allow(dead_code)]
	pub fn new_file(fname: &String) -> io::Result<Box<Lexer>> {
		let i = Rc::new(load_file(fname)?);
		Ok(Lexer::new(i))
	}

	/**
	new constructs a Lexer from a Vec<char>. 
	
	All contents of the input are treated as input text.
	*/
	pub fn new(input: Rc<Vec<char>>) -> Box<Lexer> {
		let mut lex = Box::new(Lexer{
			i:      input.clone(),
			tokens: Vec::new(),
		});
		let mut lext = 0;
		while lext < lex.i.len() {
			while lext < lex.i.len() && lex.i[lext].is_whitespace() {
				lext += 1
			}
			if lext < lex.i.len() {
				let tok = lex.scan(lext);
				lext = tok.rext;
				lex.add_token(tok)
			}
		}
		lex.add(token::Type::EOF, input.len(), input.len());
		lex
	}

	fn add(&mut self, t: token::Type, lext: usize, rext: usize) {
		self.add_token(token::new(t, lext, rext, &self.i))
	}
	
	fn add_token(&mut self, tok: Rc<token::Token>) {
		self.tokens.push(tok)
	}
	
	fn scan(&mut self, i: usize) -> Rc<token::Token> {
		let mut s: State = 0;
		let mut typ = token::Type::Error;
		let mut rext = i;

		while s != NULL_STATE {
			if rext >= self.i.len() {
				typ = ACCEPT[s];
				s = NULL_STATE
			} else {
				typ = ACCEPT[s];
				s = NEXT_STATE[s](self.i[rext]);
				if s != NULL_STATE || typ == token::Type::Error {
					rext += 1
				}
			}
		}
		return token::new(typ, i, rext, &self.i)
	}

	/// get_line_column returns the (line, column) of char[i] in the input
	#[allow(dead_code)]
	pub fn get_line_column(&self, i: usize) -> (usize, usize) {
		let mut line = 1;
		let mut col = 1;
		let mut j = 0;
		while j < i {
			match self.i[j] {
			'\n' => {
				line += 1;
				col = 1
			},
			'\t' => col += 4,
			_ => col += 1
			}
			j += 1
		}
		(line, col)
	}
	
	/// get_line_column_of_token returns the (line, column) of token[i] 
	/// in the input
	#[allow(dead_code)]
	pub fn get_line_column_of_token(&self, i: usize) -> (usize, usize) {
		self.get_line_column(self.tokens[i].lext)
	}

	// get_string returns the input string from the left extent of Token[lext] to
	// the right extent of Token[rext]
	#[allow(dead_code)]
	pub fn get_string(&self, lext: usize, rext: usize) -> String {
		let lext = self.tokens[lext].lext;
		let rext = self.tokens[rext].rext;
		self.i[lext..rext].iter().collect::<String>()
	}
	
	}
/*** End of Lexer implementation ***/


fn load_file(fname: &String) -> io::Result<Vec<char>> {
	let input = fs::read_to_string(fname)?;
	let input: Vec<char> = input.chars().collect();
	if fname.ends_with(".md") {
		load_md(input)
	} else {
		Ok(input)
	}
}

fn load_md(input: Vec<char>) -> io::Result<Vec<char>> {
    let mut i = 0;
    let mut output: Vec<char> = Vec::new();
    let mut text = true;
    while i < input.len() {
        if i < input.len() - 3
            && input[i..i + 3].into_iter().collect::<String>() == String::from("```")
        {
            text = !text;
            output.append(&mut "   ".chars().collect());
            i += 3;
        }
        if i < input.len() {
            if text {
                match input[i] {
                    '\n' => output.push('\n'),
                    _ => output.push(' '),
                }
            } else {
                output.push(input[i]);
            }
            i += 1;
        }
    }
	Ok(output)
}

#[allow(dead_code)]
fn any(r: char, set: Rc<Vec<char>>) -> bool {
	for r1 in set.iter() {
		if &r == r1 {
			return true
		}
	}
	return false
}

#[allow(dead_code)]
fn not(r: char, set: Rc<Vec<char>>) -> bool {
	for r1 in set.iter() {
		if &r == r1 {
			return false
		}
	}
	return true
}

lazy_static! {
	static ref ACCEPT: Vec<token::Type> = vec![ 
		token::Type::Error, 
		token::Type::Error, 
		token::Type::Error, 
		token::Type::Error, 
		token::Type::Error, 
		token::Type::Error, 
		token::Type::Error, 
		token::Type::Error, 
		token::Type::Type1, 
		token::Type::Type0, 
	];
}

lazy_static! {
	static ref NEXT_STATE: Vec<fn(char) -> State> = vec![  
	// Set0 
	|r| -> State { 
		match true { 
			_ if r == 'f' => return 1, 
			_ if r == 't' => return 2, 
			_ => NULL_STATE
		}
	}, 
	// Set1 
	|r| -> State { 
		match true { 
			_ if r == 'a' => return 3, 
			_ => NULL_STATE
		}
	}, 
	// Set2 
	|r| -> State { 
		match true { 
			_ if r == 'r' => return 4, 
			_ => NULL_STATE
		}
	}, 
	// Set3 
	|r| -> State { 
		match true { 
			_ if r == 'l' => return 5, 
			_ => NULL_STATE
		}
	}, 
	// Set4 
	|r| -> State { 
		match true { 
			_ if r == 'u' => return 6, 
			_ => NULL_STATE
		}
	}, 
	// Set5 
	|r| -> State { 
		match true { 
			_ if r == 's' => return 7, 
			_ => NULL_STATE
		}
	}, 
	// Set6 
	|r| -> State { 
		match true { 
			_ if r == 'e' => return 8, 
			_ => NULL_STATE
		}
	}, 
	// Set7 
	|r| -> State { 
		match true { 
			_ if r == 'e' => return 9, 
			_ => NULL_STATE
		}
	}, 
	// Set8 
	|_| -> State { 
		match true { 
			_ => NULL_STATE
		}
	}, 
	// Set9 
	|_| -> State { 
		match true { 
			_ => NULL_STATE
		}
	}, 
	];
}
